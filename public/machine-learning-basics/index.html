<!DOCTYPE html>
<html lang="en_gb">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Machine learning basics - Evolving notes on crafting a good life</title><meta name="Description" content="Evolving notes on crafting a good life"><meta property="og:title" content="Machine learning basics" />
<meta property="og:description" content="Introduction and definitions Why do we estimate f?
Purpose of ml is often to infer a function f that describes the relationship between target and features.
Can estimate f for (1) prediction or (2) inference or both.
How do we estimate f?
3 basic approaches: parametric (assume shape of f and estimate coefficients), non-parametric (also estimate shape of f), semi-parametric.
Accuracy depends on (1) irreducible error (variance of error term) and (2) reducible error (appropriateness of our model and its assumptions)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/machine-learning-basics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-10-02T08:42:30+01:00" /><meta property="og:site_name" content="Evolving notes on crafting a good life" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Machine learning basics"/>
<meta name="twitter:description" content="Introduction and definitions Why do we estimate f?
Purpose of ml is often to infer a function f that describes the relationship between target and features.
Can estimate f for (1) prediction or (2) inference or both.
How do we estimate f?
3 basic approaches: parametric (assume shape of f and estimate coefficients), non-parametric (also estimate shape of f), semi-parametric.
Accuracy depends on (1) irreducible error (variance of error term) and (2) reducible error (appropriateness of our model and its assumptions)"/>
<meta name="application-name" content="Evolving notes on crafting a good life">
<meta name="apple-mobile-web-app-title" content="Evolving notes on crafting a good life"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://example.org/machine-learning-basics/" /><link rel="prev" href="http://example.org/aws/" /><link rel="next" href="http://example.org/pandas-cookbook/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Machine learning basics",
        "inLanguage": "en_gb",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/example.org\/machine-learning-basics\/"
        },"genre": "posts","keywords": "datascience","wordcount":  2032 ,
        "url": "http:\/\/example.org\/machine-learning-basics\/","datePublished": "2020-04-01T00:00:00+00:00","dateModified": "2023-10-02T08:42:30+01:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Author"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Evolving notes on crafting a good life"></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> Home </a><a class="menu-item" href="/research/"> Research </a><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Evolving notes on crafting a good life"></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/" title="">Home</a><a class="menu-item" href="/research/" title="">Research</a><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Machine learning basics</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Author</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2020-04-01">2020-04-01</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;2032 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;10 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#general-points">General points</a></li>
    <li><a href="#process-in-practice">Process in practice</a></li>
    <li><a href="#data-processing">Data processing</a></li>
    <li><a href="#measuring-predictor-importance">Measuring predictor importance</a></li>
    <li><a href="#feature-selection">Feature selection</a></li>
    <li><a href="#factors-that-can-affect-model-performance">Factors that can affect model performance</a></li>
  </ul>

  <ul>
    <li><a href="#notes">Notes</a></li>
    <li><a href="#assessing-model-accuracy">Assessing model accuracy</a></li>
    <li><a href="#cross-validation">Cross validation</a>
      <ul>
        <li><a href="#holdout-set-approach">Holdout set approach</a></li>
        <li><a href="#leave-one-out-cross-validation">Leave one out cross-validation</a></li>
        <li><a href="#k-fold-cross-validation">k-fold cross-validation</a></li>
      </ul>
    </li>
    <li><a href="#bootstrap">Bootstrap</a></li>
    <li><a href="#confusion-matrix">Confusion matrix</a>
      <ul>
        <li><a href="#terminology">Terminology</a></li>
      </ul>
    </li>
    <li><a href="#roc-curves-and-auc">ROC curves and AUC</a></li>
    <li><a href="#precision-recall-curves">Precision-recall curves</a></li>
    <li><a href="#learning-curves">Learning curves</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="introduction-and-definitions">Introduction and definitions</h1>
<p><strong>Why do we estimate f?</strong></p>
<ul>
<li>
<p>Purpose of ml is often to infer a function f that describes the relationship between target and features.</p>
</li>
<li>
<p>Can estimate f for (1) prediction or (2) inference or both.</p>
</li>
</ul>
<p><strong>How do we estimate f?</strong></p>
<ul>
<li>
<p>3 basic approaches: parametric (assume shape of f and estimate coefficients), non-parametric (also estimate shape of f), semi-parametric.</p>
</li>
<li>
<p>Accuracy depends on (1) irreducible error (variance of error term) and (2) reducible error (appropriateness of our model and its assumptions)</p>
</li>
</ul>
<p><strong>Ingredients to statistical learning</strong></p>
<ul>
<li>
<p>Specify aim</p>
</li>
<li>
<p>Gather and pre-process data</p>
</li>
<li>
<p>Select a learning algorithm</p>
</li>
<li>
<p>Apply learning algorithm to data to build (and train) a model</p>
</li>
<li>
<p>Assess model performance (by testing) and tune model</p>
</li>
<li>
<p>Make predictions</p>
</li>
</ul>
<p><strong>Types of learning</strong></p>
<ul>
<li>
<p>Supervised (labelled examples)</p>
</li>
<li>
<p>Unsupervised (unlabelled examples)</p>
</li>
<li>
<p>Semi-supervised (labelled and unlabelled examples)</p>
</li>
<li>
<p>Reinforcement</p>
</li>
</ul>
<p><strong>The trade-off between prediction accuracy and model interpretability</strong></p>
<ul>
<li>Linear models vs non-linear models (hard to interpret models often predict more accurately).</li>
</ul>
<p><strong>Supervised vs. unsupervised learning</strong></p>
<p><strong>Regression vs classification problems</strong></p>
<ul>
<li>Classification assigns categorical labels, regression real-valued labels to unlabelled examples.</li>
</ul>
<p><strong>Hyperparameters vs parameters</strong></p>
<ul>
<li>
<p>Hyperparameters determine how the algorithm works and are set by the researcher.</p>
</li>
<li>
<p>Parameters determine the shape of the model and are estimated.</p>
</li>
</ul>
<p><strong>Model-based vs instance-based learning</strong></p>
<ul>
<li>Model-based algorithms estimate and then use parameters to make predictions (i.e. can discard training data once you have estimate), instance-based algorithms (e.g. KNN) use the entire training dataset.</li>
</ul>
<p><strong>Deep vs shallow learning</strong></p>
<ul>
<li>Shallow learning algorithms learn parameters directly from features, deep learning algorithms (deep neural network) learn them from the output of preceeding layers.</li>
</ul>
<p>Sources of prediction error</p>
<ul>
<li>
<p>If we think about $Y = f(X) + \epsilon$</p>
</li>
<li>
<p>Reducible error stems from our imperfect ability to estimate the model (the systematic relationship between X and y) i.e. the difference between $f$ and $\hat{f}$.</p>
</li>
<li>
<p>Irreducible error stems from the fact that even if we could perfectly model the relationship between X and Y, Y would still be a function of the error term $\epsilon$, which we cannot reduce. This could be variables other than X that predict Y, or random variation in Y (e.g. purchasing behaviour on given day influenced by car breakdown).</p>
</li>
</ul>
<p>Practical tips</p>
<ul>
<li>One way to get a sense of how non-linear the problem is, is to compare the MSE of a simple linear model and a more complex model. If the two are very close, then assuming linearity and using a simple model is preferrable.</li>
</ul>
<h1 id="feature-engineering">Feature engineering</h1>
<h2 id="general-points">General points</h2>
<ul>
<li>Having many uninformative features in your model might lower performance as it makes is more likely that the model overfits (e.g. including country names when predicting life satisfaction and using OECD sample finds that &ldquo;w&rdquo; in country name predicts high life satisfaction because of Norway, Switzerland, New Zealand, and Sweden. But this doesn&rsquo;t generalize to Rwanda and Zimbabwe). Hence, the more uninformative features, the bigger the chance that the model will find a pattern by chance in one of them in your training set.</li>
</ul>
<h2 id="process-in-practice">Process in practice</h2>
<ol>
<li>Brainstorm features</li>
<li>Decide what features to create</li>
<li>Create the features</li>
<li>Test impact on model performance</li>
<li>Interacting on features is useful</li>
<li>Iterate (go to 3 or 1)</li>
</ol>
<p>Stuff to try:</p>
<ul>
<li>Ratios</li>
<li>Counts</li>
<li>Cutoff points</li>
<li>Iterate on features (change cutoff and see whether it makes a difference)</li>
<li>Rate of Change in Values</li>
<li>Range of Values</li>
<li>Density within Intervals of Time</li>
<li>Proportion of Instances of Commonly Occurring Values</li>
<li>Time Between Occurrences of Commonly Occurring Values</li>
</ul>
<h2 id="data-processing">Data processing</h2>
<ul>
<li>
<p>Data transformations for individual predictors</p>
</li>
<li>
<p>Data transformations for multiple predictors</p>
</li>
<li>
<p>Dealing with missing values</p>
</li>
<li>
<p>Removing predictors</p>
</li>
<li>
<p>Adding predictors</p>
</li>
<li>
<p>Binning predictors</p>
</li>
</ul>
<h2 id="measuring-predictor-importance">Measuring predictor importance</h2>
<ul>
<li>
<p>Numeric outcomes</p>
</li>
<li>
<p>Categorical outcomes</p>
</li>
<li>
<p>Other approaches</p>
</li>
</ul>
<h2 id="feature-selection">Feature selection</h2>
<ul>
<li>
<p>Consequences of using non-informative predictors</p>
</li>
<li>
<p>Approaches for reducing the number of predictors</p>
</li>
<li>
<p>Wrapper methods</p>
</li>
<li>
<p>Filter methods</p>
</li>
<li>
<p>Selection bias</p>
</li>
</ul>
<h2 id="factors-that-can-affect-model-performance">Factors that can affect model performance</h2>
<ul>
<li>
<p>Type III errors</p>
</li>
<li>
<p>Measurement errors in the outcome</p>
</li>
<li>
<p>Measurement errors in the predictors</p>
</li>
<li>
<p>Distretising continuous outcomes</p>
</li>
<li>
<p>When should you trust your model&rsquo;s prediction?</p>
</li>
<li>
<p>The impact of a large sample</p>
</li>
</ul>
<h1 id="model-selection-and-assessment">Model selection and assessment</h1>
<h2 id="notes">Notes</h2>
<p>The ultimate trade-off for model performance is between bias and variance. Simple models will have higher bias and lower variance, more complex models lower bias but higher variance (becuse they tend to overfit the training data).</p>
<p>Two things mainly determine model performance:</p>
<ul>
<li>Model complexity (validation curves in PDSH)</li>
<li>Training data size (learning curves in PDSH)</li>
</ul>
<p>What to do when model is underperforming?</p>
<ol>
<li>Use a more complicated/flexible model</li>
<li>Use a less complicated/flexible model</li>
<li>Gather more training samples (make data longer)</li>
<li>Gather more data for additional features for each sample (make data wider)</li>
</ol>
<p>Train and test vs cross-validation</p>
<ul>
<li>These approaches are complementary, as nicely explained in the <a href="https://scikit-learn.org/stable/modules/cross_validation.html" target="_blank" rel="noopener noreffer ">Scikit-learn</a> docs: the generall process is to split the data into a training and a testing dataset, and then to use cross-validation on the training data to find the optimal hyperparameters.</li>
</ul>
<h2 id="assessing-model-accuracy">Assessing model accuracy</h2>
<p>Measuring the quality of fit</p>
<ul>
<li>
<p>MSE for regressions.</p>
</li>
<li>
<p>Error rate for classification.</p>
</li>
<li>
<p>Beware of overfitting! Maximise mse or error rate for testing data, not for training data (overfitting).</p>
</li>
<li>
<p>Overfitting definition: situation where a simpler model with a worse training score would have achieved a better testing score.</p>
</li>
</ul>
<p>The bias-variance trade-off</p>
<ul>
<li>
<p>MSE comprises (1) squared bias of estimate, (2) variance of estimate, and (3) variance of error. We want to minimise 1 and 2 (3 is fixed).</p>
</li>
<li>
<p>Relationship between MSE and model complexity is U-shaped, because variance increases and bias decreases with complexity. We want to find optimal balance.</p>
</li>
</ul>
<p>Classification setting</p>
<ul>
<li>
<p>Bayesian classifier as unattainable benchmark (we don&rsquo;t know P(y|x)).</p>
</li>
<li>
<p>KNN one approach to estimate P(y|x), then use bayesian classifier.</p>
</li>
<li>
<p>Intuition as for MSE error: testing error rate is U-shaped in K (higher K means more flexibel model).</p>
</li>
</ul>
<h2 id="cross-validation">Cross validation</h2>
<p>Use cases:</p>
<ul>
<li>Model assessment (&ldquo;how good is model fit?&rdquo;)</li>
<li>Model selection (hypterparameter tuning)</li>
</ul>
<h3 id="holdout-set-approach">Holdout set approach</h3>
<p>How it works:</p>
<ul>
<li>Split data into training and test data, fit model on the training data, assess on the test data.</li>
</ul>
<p>Advantages:</p>
<ul>
<li>Conceptually simple and computationally cheap.</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Very sensitive to train-test split, especially for small samples.</li>
<li>Because we only use a fraction of the available data to train the model, model fit is poorer comparated to using entire dataset, and thus we tend to overestimate test error.</li>
</ul>
<h3 id="leave-one-out-cross-validation">Leave one out cross-validation</h3>
<p>How it works:</p>
<ul>
<li>If we have <code>n</code> observations, fit model using <code>n-1</code> observations and calculate MSE for nth observation. Repeat n times and then average MSEs to get test error rate.</li>
</ul>
<p>Advantage:</p>
<ul>
<li>Deals with both problems of holdout set approach.</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>Computationally expensive or prohibitive for large ns</li>
</ul>
<h3 id="k-fold-cross-validation">k-fold cross-validation</h3>
<p>How it works:</p>
<ul>
<li>Similar to LOOCV (which is a special case where k = n), but we split data into k groups (folds), and then use each of them in turn as the test training set while training the model on the remaining k-1 folds. We again average the k MSEs to get the overall test error rate.</li>
</ul>
<p>Advantage:</p>
<ul>
<li>Computationally cheaper than LOOCV</li>
<li>Beats LOOCV in terms of MSE because it trades-off bias and variance in a more balanced way: LOOCV has virtually no bias (as we use almost the entire data to fit the model each time) but has higher variance because all k MSE estimates are highly correlated (because each model is fit with almost identical data). In contrast, training data for k-fold CV is less similar, meaning MSEs are less correlated, meaning reduction in variance from averaging is greater.</li>
</ul>
<h2 id="bootstrap">Bootstrap</h2>
<p>Use cases</p>
<ul>
<li>Model assessment (&ldquo;how good is parameter fit?&rdquo;)</li>
</ul>
<p>How it works</p>
<ul>
<li>To get an estimate for our model fit, we would ideally want to fit the model on many random population samples, so that we could then calculate means and standard deviations of our model assessment metric of interest.</li>
<li>We can&rsquo;t draw multiple samples from the population, but the bootstrap mimics this approach by repeatedly sampling (with replacement) from our original sample.</li>
</ul>
<h2 id="confusion-matrix">Confusion matrix</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">23124</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ymodel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ymodel</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;Blues&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Predicted value&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;True value&#34;</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png"
        data-srcset="machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png, machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png 1.5x, machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png 2x"
        data-sizes="auto"
        alt="machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png"
        title="machine-learning-basics_files/figure-markdown_strict/cell-2-output-1.png" /></p>
<h3 id="terminology">Terminology</h3>
<p>Can think of &ldquo;+&rdquo; as &ldquo;diseases&rdquo; or &ldquo;alternative hypothesis&rdquo;, and of &ldquo;-&rdquo; as &ldquo;no disease&rdquo; or &ldquo;null hypothesis&rdquo;.</p>
<table>
<thead>
<tr>
<th></th>
<th>Predicted</th>
<th style="text-align:center">-</th>
<th style="text-align:center">+</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>True</td>
<td>-</td>
<td style="text-align:center">True negative (TN)</td>
<td style="text-align:center">False positive (FP)</td>
<td>N</td>
</tr>
<tr>
<td></td>
<td>+</td>
<td style="text-align:center">False negative (FN)</td>
<td style="text-align:center">True positive (TP)</td>
<td>P</td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align:center">N*</td>
<td style="text-align:center">P*</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>True positive rate: $\frac{TP}{TP + FN} = \frac{TP}{P}$, is the proportion of positives that we correctly predict as such. Also called sensitivity, of hit rate, or recall.</p>
</li>
<li>
<p>False positive rate: $\frac{FP}{FP + TN} = \frac{FP}{N}$, is the proportion of negatives events we incorrectly predict as positives. Also called the alarm rate or inverted specificity, where specificity is $\frac{TN}{FP + TN} = \frac{TN}{N}$.</p>
</li>
<li>
<p>Precision: $\frac{TP}{TP + FP} = \frac{TP}{P*}$.</p>
</li>
<li>
<p>Precision and recall originate in the field of information retrieval (e.g. getting documents from a query). In its original context, precision is useful documents as a proportion of all retrieved documents, recall the retrieved useful documents as a proportion of all available useful documents. In the context of machine learning, we can think of precision as positive predictive power (how good is the model at predicting the positive class), while recall is the same as sensitivity &ndash; the proportion of all events that were successfully predicted.</p>
</li>
</ul>
<h2 id="roc-curves-and-auc">ROC curves and AUC</h2>
<ul>
<li>
<p>Plots the trade-off between the false positive rate (x-axis) and the true positive rate (y-axis) - the trade-off between the false alarm rate and the hit rate.</p>
</li>
<li>
<p>The ROC is useful because it directly shows false/true negatives (on the x-axis) and false/true positives (on the y-axis) for different thresholds and thus helps choose the best threshold, and because the area under the curve (AUC) can be interpreted as an overall model summary, and thus allows us to compare different models.</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">plot_roc_curve</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">23124</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ymodel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">roc</span> <span class="o">=</span> <span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">_</span> <span class="o">=</span> <span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">roc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png"
        data-srcset="machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png, machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png 1.5x, machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png 2x"
        data-sizes="auto"
        alt="machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png"
        title="machine-learning-basics_files/figure-markdown_strict/cell-3-output-1.png" /></p>
<h2 id="precision-recall-curves">Precision-recall curves</h2>
<ul>
<li>
<p>The precision-recall curve is particularly useful when we have much more no-event than event cases. In this case, we&rsquo;re often not interested much in correctly predicting no-events but focused on correctly predicting events. Because neither precision nor recall use true negatives in their calculations, they are well suited to this context (<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432" target="_blank" rel="noopener noreffer ">paper</a>).</p>
</li>
<li>
<p>The precision recall curve plots precision (y-axis) and recall (x-axis). An unskilled model is a horizontal line at hight equal to the proportion of events in the sample. We can use ROC to compare models as different thresholds, or the F-score (the harmonic mean between precision and recall) at a specific threshold.</p>
</li>
<li>
<p>Use precision-recall curves if classes are imbalanced, in which case ROC can be misleading (see example in last section <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/" target="_blank" rel="noopener noreffer ">here</a>).</p>
</li>
<li>
<p>Shape of curve: recall increases monotonically as we lower the threshold (move from left to right in the graph) because we&rsquo;ll find more and more true positives (&ldquo;putting ones from the false negative to the true positive bucket&rdquo;, which increases the numerator but leaves the denominator unchanged), but precision needn&rsquo;t fall monotonically, because we also increase false positives (both the numerator and the denominator increase as we lower the threshold, and the movement of recall depends on which increases faster, which depends on the sequence of ordered predicted events). See <a href="https://stats.stackexchange.com/a/183506" target="_blank" rel="noopener noreffer ">here</a> for a useful example.</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_precision_recall_curve</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">23124</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ymodel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot_precision_recall_curve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png"
        data-srcset="machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png, machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png 1.5x, machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png 2x"
        data-sizes="auto"
        alt="machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png"
        title="machine-learning-basics_files/figure-markdown_strict/cell-4-output-1.png" /></p>
<h2 id="learning-curves">Learning curves</h2>
<h1 id="sources">Sources</h1>
<ul>
<li><a href="https://www.statlearning.com" target="_blank" rel="noopener noreffer ">An introduction to statistical learning</a></li>
<li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" target="_blank" rel="noopener noreffer ">Hands on machine learning with scikit-learn, keras, and tenserflow</a></li>
<li><a href="https://www.oreilly.com/library/view/python-data-science/9781491912126/" target="_blank" rel="noopener noreffer ">Python Data Science Handbook</a></li>
<li><a href="http://themlbook.com" target="_blank" rel="noopener noreffer ">The hundred-page machine learning book</a></li>
<li><a href="http://appliedpredictivemodeling.com" target="_blank" rel="noopener noreffer ">Applied predictive modeling</a></li>
<li><a href="https://www.youtube.com/watch?time_continue=109&amp;v=drUToKxEAUA&amp;feature=emb_logo" target="_blank" rel="noopener noreffer ">video</a></li>
<li>mlmastery <a href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/" target="_blank" rel="noopener noreffer ">article</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2023-10-02</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/datascience/">datascience</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/aws/" class="prev" rel="prev" title="AWS"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>AWS</a>
            <a href="/pandas-cookbook/" class="next" rel="next" title="Pandas cookbook">Pandas cookbook<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.111.3">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2019 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
