{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fast Pandas\n",
    "\n",
    "- hide: true\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [pandas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The problem:\n",
    "\n",
    "- I often work with largish datasets (e.g. 10s or 100s of GB) that are not big enough to warrant all the heavy machinery of big data work but are still too big to just load into Pandas and process on my 8GB-RAM MacBook.\n",
    "\n",
    "\n",
    "Two broad solutions:\n",
    "\n",
    "- Use a vm\n",
    "\n",
    "- Use my MacBook effectively\n",
    "\n",
    "\n",
    "Workflow:\n",
    "\n",
    "- Test stuff locally with small datasets\n",
    "\n",
    "- Process large datasets on AWS vm\n",
    "\n",
    "\n",
    "Work to do:\n",
    "\n",
    "- Set up vm with Terraform\n",
    "\n",
    "- Manage vm\n",
    "\n",
    "- Over time, use best-practices for effective MacBook use on vm for optimal speed and learning (e.g. Dask, etc.)\n",
    "\n",
    "\n",
    "Best practices for working with largish data locally:\n",
    "\n",
    "- Read [these](https://pythonspeed.com/memory/) awesome articles. Seriously, before doing anything, read them.\n",
    "\n",
    "- Also have a look at [this](https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c)\n",
    "\n",
    "- Read data in chunks\n",
    "\n",
    "- Read dates [efficiently](- [Use cache to read dates](https://stackoverflow.com/questions/14446744/speed-improvement-on-large-pandas-read-csv-with-datetime-index))\n",
    "\n",
    "- [Optimise column types](https://www.dataquest.io/blog/pandas-big-data/)\n",
    "\n",
    "- Delete unnecessary columns\n",
    "\n",
    "- [Choose efficient storage format](https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d)\n",
    "\n",
    "\n",
    "Fast computations\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/dev/user_guide/enhancingperf.html\n",
    "\n",
    "- https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "\n",
    "\n",
    "Useful libraries\n",
    "\n",
    "- [vaex, for fast dataframe operations with focus on visualisation and exploration](https://vaex.readthedocs.io/en/latest/tutorial.html)\n",
    "\n",
    "- [Modin, speeds up Pandas with minimal effort using Dask under the hood](https://github.com/modin-project/modin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "blog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
